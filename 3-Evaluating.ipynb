{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ipynb 파일이 분리되어 있는 관계로 이전 파일의 실행 내역 복사\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"turnover.csv\")\n",
    "\n",
    "data.salary = data.salary.astype('category')\n",
    "data.salary = data.salary.cat.reorder_categories(['low', 'medium', 'high'])\n",
    "data.salary = data.salary.cat.codes\n",
    "\n",
    "departments = pd.get_dummies(data.department)\n",
    "departments = departments.drop(\"technical\", axis=1)\n",
    "data = data.drop(\"department\", axis=1)\n",
    "data = data.join(departments)\n",
    "\n",
    "target = data.left\n",
    "features = data.drop(\"left\", axis=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "target_train, target_test, features_train, features_test = train_test_split(target, features, test_size=0.25)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluating the turnover prediction model\n",
    "\n",
    "### 퇴직율 classifier 조정하기\n",
    "좀 더 나은 결과를 얻기 위해 overfitting 제거 작업 수행하는데, 위 결과를 보면 아래와 같은 overfitting이 발생\n",
    "- training 데이터의 정확도 : 100%\n",
    "- Testing 데이터의 정확도 : 97.65%\n",
    "\n",
    "그렇다면 overfitting을 줄이거나 없애기 위해 무엇을 조정해야 할까?\n",
    "- tree의 최대 단계 수를 제한(예, 5단계까지만 tree 생성)\n",
    "- 개별 단계(leaf 또는 node)의 크기를 제한(예, 노드별로 최대 100명까지만 허용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 먼저 단계 수(depth) 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tree의 단계 수르 5개로 제한\n",
    "model_depth_5 = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "\n",
    "# 모델 fitting\n",
    "model_depth_5.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.537558894123919"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단계 수를 제한 한 다음에 train 데이터 대한 예측결과의 정확도를 점수로 환산해보면..\n",
    "model_depth_5.score(features_train, target_train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.493333333333325"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터 정확도를 점수로 확인\n",
    "model_depth_5.score(features_test, target_test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다음으로 노드 크기(인원) 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=200, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 노드의 크기를 200명으로 제한\n",
    "model_sample_200 = DecisionTreeClassifier(min_samples_leaf=200, random_state=42)\n",
    "\n",
    "# 모델 fitting\n",
    "model_sample_200.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.466263667881591"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 노드 크기를 제한 한 다음에 train 데이터와 test 데이터에 대한 예측결과의 정확성을 점수로 환산해보면..\n",
    "model_sample_200.score(features_train, target_train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.439999999999998"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터 정확성 확인\n",
    "model_sample_200.score(features_test, target_test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 방식으로 하면 각각의 정확도는 떨어지지만 두 데이터셋 간의 차이(거리)는 줄어든다.</p>\n",
    "즉, overfitting이 줄어들면서 더 현실적인 예측모델이 된다.\n",
    "\n",
    "(Depth = 5와 sample =200을 합치면 sample=200의 결과와 같다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지는 정확도(accuracy)만을 계산했다. 그러나 정확도 지표 하나만으로는 최적의 모델을 찾는데 역부족.</p>\n",
    "왜냐고?\n",
    "일반적인 Accuracy 점수는 분리된 데이터군(class, 여기서는 재직자와 퇴직자군)에 관한 정보를 보여줄수 없기 때문.</br>\n",
    "예) 재직자의 76% = \"모두가 남아있을\"거라는 예측의 정확도가 76%의 확률\n",
    "\n",
    "그래서 Confustion matrix를 사용해서 예측오류(prediction error)를 줄이는 방법을 찾아내야 한다.\n",
    "- 퇴직자에 대한 정확도 평가 --> Recall 점수 산정 : 퇴직자인데 퇴직자 아니라고 예측한 비율(FN)\n",
    "- 재작자에 대한 정확도 평가 --> Specificity 점수 산정 : 퇴직자 아닌데 퇴직자라고 예측한 비율(FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정밀도(precision)의 accuracy metircs 계산하기\n",
    "\n",
    "정밀도 : 퇴직할 것이라고 예측한 사람들 중 실제로 퇴직한 사람들의 비율</p>\n",
    "Precision score는 classification 알고리즘의 정확도를 재는 중요한 측정지표(metrics)로 True Positive를 True Positive와 False Positive의 합으로 나눈 것.\n",
    "\n",
    " = # of True Positives / # of True Positivies + # of False Positives\n",
    "\n",
    "- True Positives = 실제 퇴직한 직원을 정확하게 예측한 경우\n",
    "- False Positives = 퇴직을 안했는데 퇴직할 것이라고 잘못 예측한 경우\n",
    "\n",
    "- 정밀도(precision score)가 가장 높은 것은 1, 가장 낮은 것은 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94481236203090513"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision score를 계산할 함수 호출\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# features 데이터를 이용해서 어떤 직원이 이직할 것인지를 예측\n",
    "prediction = model.predict(features_test)\n",
    "\n",
    "# target 데이터에 대한 예측비교를 통해 precision score 계산\n",
    "precision_score(target_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 재현율(Recall)의 accuracy metircs 계산하기\n",
    "\n",
    "재현율 : 퇴직할 것이라고 예측했는데 실제로 그 예측이 맞을 확률</p>\n",
    "Recall score는 classification 알고리즘의 정확도를 재는 중요한 측정지표(metrics)로 일명 민감도(Sensitivity)라고도 함\n",
    "\n",
    " = # of True Positives / # of True Positivies + # of False Negatives\n",
    "\n",
    "- False Negatives가 없으면 Recall score는 최대치가 됨 \n",
    "- 재현율(recall score)이 가장 높은 것은 1, 가장 낮은 것은 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96851248642779586"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall score를 계산하는 함수 호출\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# 퇴직자를 예측할 초기 모델 수립 : features test 데이터를 대상으로 \n",
    "prediction = model.predict(features_test)\n",
    "\n",
    "# 대상데이터로 예측한 결과와 비교하여 recall score 계산\n",
    "recall_score(target_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 재직자와 퇴직자 모두를 대상으로 분석하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recall 점수 -> False Negative의 수에 비중을 둠 \n",
    "- Specificity 점수 -> False Positive의 수에 비중을 둠\n",
    "\n",
    "여기서는 퇴직자를 예측하는 것이므로,</p>\n",
    "Recall 점수는 퇴직자를 대상으로 하는 예측분석에, Specificity 점수는 재직자를 대상으로 하는 예측분석에 유용\n",
    "\n",
    "그러나, 분석 대상을 하나만으로 한정하면 다른 대상에 대한 예측의 정확도(accuracy)는 떨어짐</p>\n",
    "그래서 두 대상 모두에 대해 좋은 예측력을 얻기 위해서는 AUC(Area Under Curve) 점수를 사용\n",
    "\n",
    "#### AUC 점수\n",
    "수직 축 : Recall </p>\n",
    "수평 축 : 1 - Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97453549383249105"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROC와 AUC 점수를 계산하는 함수 호출 : roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 퇴직자 예측을 위한 모델 수립\n",
    "prediction = model.predict(features_test)\n",
    "\n",
    "# 예측값과 대상데이터와의 비교를 통해 ROC와 AUC 점수 계산\n",
    "roc_auc_score(target_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance\n",
    "분석대상 대조군(class)간의 데이터 차이(imbalance). <b>지금까지의 분석은 이 class imbalance 상태에서 이루어진 것임</b> </p>\n",
    "recall과 precision 점수의 차이에서 봤듯이, class imbalance는 예측결과에 심각한 영향을 미침</p>\n",
    "\n",
    "class imbalance 문제 해결 방법\n",
    "- 각각의 class에 다른 가중치를 부여하여 균형을 맞춤(=balanced) : class_weight\n",
    "- over-sampling\n",
    "- under-sampling\n",
    "- Synthetic Minority Oversampling Technique(SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balancing classes\n",
    "Decision tree에서 class imbalance를 해소하기 위해서는 \n",
    "- 각각의 class(분석대상 군)에 가중치를 부여 : class_weight='balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.733333333333334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DecisionTreeClassifier 초기화\n",
    "model_depth_5b = DecisionTreeClassifier(max_depth=5, class_weight='balanced', random_state=42)\n",
    "\n",
    "# 모델 fitting\n",
    "model_depth_5b.fit(features_train, target_train)\n",
    "\n",
    "# 테스트 데이터를 대상으로 예측점수 산정\n",
    "model_depth_5b.score(features_test, target_test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employee attrition 모델의 비교\n",
    "\n",
    "Decision tree에서 불필요한 tree의 가지(=단계)를 줄이는 pruned tree를 사용하여 'balanced model'과 'imbalanced model'을 비교 \n",
    "(여기서는 max_depth=7로 조정)\n",
    "\n",
    "imbalanced model은 recall 점수와 ROC/AUC 점수를 통해 위에서 이미 만들어 봤으니 이제는 같은 방법으로 balanced model을 만들어 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class balance model 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968512486428\n",
      "0.974535493832\n",
      "0.940282301846\n",
      "0.962364551418\n"
     ]
    }
   ],
   "source": [
    "# 이전에 계산했던 recall score와 ROC/AUC score 조회\n",
    "print(recall_score(target_test,prediction))\n",
    "print(roc_auc_score(target_test,prediction))\n",
    "\n",
    "# class balance를 위한 비교 모델 생성 - class_weight 사용\n",
    "model_depth_7b = DecisionTreeClassifier(max_depth=7, class_weight='balanced', random_state=42)\n",
    "\n",
    "# 새로운 모델(balanced model)을 train 데이터에 fitting\n",
    "model_depth_7b.fit(features_train,target_train)\n",
    "\n",
    "# test 데이터를 대상으로 예측\n",
    "prediction_b = model_depth_7b.predict(features_test)\n",
    "\n",
    "# 새로운 recall score와 ROC/AUC score를 각각 출력\n",
    "print(recall_score(target_test, prediction_b))\n",
    "print(roc_auc_score(target_test, prediction_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
