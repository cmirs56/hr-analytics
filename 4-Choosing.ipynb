{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=7,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ipynb 파일이 분리되어 있는 관계로 이전 파일의 실행 내역 복사\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"turnover.csv\")\n",
    "\n",
    "data.salary = data.salary.astype('category')\n",
    "data.salary = data.salary.cat.reorder_categories(['low', 'medium', 'high'])\n",
    "data.salary = data.salary.cat.codes\n",
    "\n",
    "departments = pd.get_dummies(data.department)\n",
    "departments = departments.drop(\"technical\", axis=1)\n",
    "data = data.drop(\"department\", axis=1)\n",
    "data = data.join(departments)\n",
    "\n",
    "target = data.left\n",
    "features = data.drop(\"left\", axis=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "target_train, target_test, features_train, features_test = train_test_split(target, features, test_size=0.25)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "model_best = DecisionTreeClassifier(max_depth=7, class_weight='balanced', random_state=42)\n",
    "model_best.fit(features_train,target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최선의 퇴직율 예측 모델 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "Hyperparameter : 데이터를 학습시킬 때 사람이 직접 튜닝을 해 줘야 하는 변수들</p>\n",
    "예) max_depth를 어떻게 잡아야 최적인지 알 수가 있나?\n",
    "\n",
    "<b>Hyperparameter를 튜닝하는 방법</b>\n",
    "1. Grid Search :\n",
    "Hyperparameter의 대략적인 법위를 지정하고, 일정한 간격으로 값을 선택하여 학습\n",
    "2. Random Search : \n",
    "Hyperparameter의 대략적인 범위를 지정하고 그 범위내에서 무작위로 값을 선택하여 학습\n",
    "3. Bayesian optimization : \n",
    "기존 학습결과로 Hyperparameter의 산전분포를 가정하고, 최적의 Hyperparameter로 가정되는 값의 학습결과를 얻은 후에 다시 사후분포를 결정하는 작업을 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation : sklearn을 사용\n",
    "\n",
    "GridSearch를 그대로 사용하면 overfitting의 위험성이 있음</p>\n",
    "=> 테스트 데이터셋을 여러 개(=k개)로 분리하여 각각 번갈아가며 훈련데이터셋과 테스트데이터셋으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98467688  0.988       0.97133333  0.96333333  0.956       0.982       0.988\n",
      "  0.99133333  1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "# cross validation을 수행할 함수 호출 : cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 데이터셋 갯수(k)를 10개(fold)로 했을 때 cross validation 점수를 구한다\n",
    "print(cross_val_score(model, features, target, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>최적의 hyperparameter를 찾기 위한 여정</b> : GridSearchCV</p>\n",
    "1. maximum depth와 minimum sample size 등의 hyperparameter에 대입 가능한 수의 값을 만들어서 통제하고</br>\n",
    "2. 'parameters'라는 딕셔너리를 생성</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파라미터 딕셔너리 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max_depth를 위한 값 생성\n",
    "depth = [i for i in range(5,21)]\n",
    "\n",
    "# minimum sample size를 위한 값 생성\n",
    "samples = [i for i in range(50,500,50)]\n",
    "\n",
    "# 위의 두 값을 파라미터로 사용할 딕셔너리 생성\n",
    "parameters = dict(max_depth = depth, min_samples_leaf = samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>GridSearch를 통해 최적의 파라미터 도출</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'min_samples_leaf': 50}\n"
     ]
    }
   ],
   "source": [
    "# GridSearch를 구현할 함수 호출\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 파라미터 설정 - 앞에서 설정\n",
    "# parameters = dict(max_depth = depth, min_samples_leaf = samples)\n",
    "\n",
    "# 앞에서 작성한 기본 모델과 파라미터를 사용해서 'param_search' 함수 초기화\n",
    "param_search = GridSearchCV(model, parameters)\n",
    "\n",
    "# param_search를 훈련 데이터셋에 fitting\n",
    "param_search.fit(features_train, target_train)\n",
    "\n",
    "# 최적의 parameter 출력\n",
    "print(param_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting attrition에 필요한 중요한 특성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Feature importances</b></p>\n",
    "Decision Tree가 만들어지면 sklearn은 feature importance를 쉽게 계산할 수 있음\n",
    "- importance = 선택된 feature에 대한 Gini의 상대적인 감소\n",
    "- 모든 feature에 대한 계산이 끝나면 전체 값은 다시 100%로 설정됨\n",
    "- %간 높은 feature일수록 더 중요 -> 중요하지 않은 feature는 제거하는 게 나음\n",
    "\n",
    "<b>※ HR Analytics에서 Decision Tree가 많이 쓰이는 이유</b></p>\n",
    "=> interpretability(해석편리성)\n",
    "즉, 예측(여기서는 퇴직) 관련 개별 feature의 영향력을 수량화하여 그 중에서 어떤 게 중요한 건지를 식별할 수 있게 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### 중요도 해석\n",
    "#### 중요한 feature의 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>satisfaction_level</th>\n",
       "      <td>0.459330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_spend_company</th>\n",
       "      <td>0.368838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_evaluation</th>\n",
       "      <td>0.102196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_montly_hours</th>\n",
       "      <td>0.042739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_project</th>\n",
       "      <td>0.023321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>0.001745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>0.001575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandD</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accounting</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marketing</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_mng</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work_accident</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IT</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       importance\n",
       "satisfaction_level       0.459330\n",
       "time_spend_company       0.368838\n",
       "last_evaluation          0.102196\n",
       "average_montly_hours     0.042739\n",
       "number_project           0.023321\n",
       "sales                    0.001745\n",
       "salary                   0.001575\n",
       "support                  0.000257\n",
       "promotion_last_5years    0.000000\n",
       "RandD                    0.000000\n",
       "accounting               0.000000\n",
       "hr                       0.000000\n",
       "management               0.000000\n",
       "marketing                0.000000\n",
       "product_mng              0.000000\n",
       "Work_accident            0.000000\n",
       "IT                       0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importances 계산\n",
    "feature_importances = model_best.feature_importances_\n",
    "\n",
    "# feature 목록 생성\n",
    "feature_list = list(features)\n",
    "\n",
    "# feature list를 DataFrame안에 집어넣기\n",
    "relative_importances = pd.DataFrame(index=feature_list, data = feature_importances, columns = [\"importance\"])\n",
    "\n",
    "# 가장 중요한 featuer를 먼저 보기 위해 DataFrame 정렬\n",
    "relative_importances.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 중요한 feature를 선택하여 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# relative_importance가 1% 이상인 feature만 선택\n",
    "selected_features = relative_importances[relative_importances.importance > 0.01]\n",
    "\n",
    "# 위의 선택된 feature들을 list로 만들기\n",
    "selected_list = selected_features.index\n",
    "\n",
    "# 위의 선택된 feature(selected_list)를 features_train 데이터와 features_test 데이터에 적용\n",
    "features_train_selected = features_train[selected_list]\n",
    "features_test_selected = features_test[selected_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       satisfaction_level  last_evaluation  number_project  \\\n",
      "2032                 0.54             0.94               4   \n",
      "1160                 0.36             0.73               4   \n",
      "11615                0.87             0.89               4   \n",
      "2166                 0.75             0.70               3   \n",
      "5668                 0.77             0.55               3   \n",
      "4564                 0.52             0.47               3   \n",
      "10250                0.64             1.00               4   \n",
      "854                  0.79             0.90               5   \n",
      "1941                 0.81             0.85               4   \n",
      "13349                0.75             0.93               3   \n",
      "12091                0.89             1.00               5   \n",
      "5520                 0.85             0.57               4   \n",
      "13550                0.76             0.81               4   \n",
      "7536                 0.51             0.93               3   \n",
      "547                  0.37             0.50               2   \n",
      "9038                 0.84             0.65               4   \n",
      "12363                0.72             0.96               5   \n",
      "4519                 0.44             0.45               2   \n",
      "1296                 0.46             0.52               2   \n",
      "6562                 0.57             0.50               4   \n",
      "8445                 0.70             0.80               5   \n",
      "5492                 0.37             0.46               3   \n",
      "4697                 0.62             0.49               4   \n",
      "11575                0.49             0.68               3   \n",
      "7606                 0.57             0.98               3   \n",
      "13600                0.16             0.42               3   \n",
      "7596                 0.84             0.54               4   \n",
      "10073                0.23             0.87               5   \n",
      "13397                0.80             0.75               4   \n",
      "9802                 0.84             0.56               3   \n",
      "...                   ...              ...             ...   \n",
      "11193                0.75             0.60               4   \n",
      "5040                 0.73             0.66               6   \n",
      "6778                 0.34             0.67               5   \n",
      "1533                 0.44             0.53               2   \n",
      "1789                 0.41             0.46               2   \n",
      "2997                 0.72             0.47               5   \n",
      "2384                 0.50             0.81               3   \n",
      "11349                0.95             0.90               4   \n",
      "4993                 0.92             0.62               4   \n",
      "7627                 0.58             0.86               3   \n",
      "3611                 0.60             0.99               4   \n",
      "12281                0.27             0.56               3   \n",
      "13901                0.83             0.48               4   \n",
      "120                  0.14             0.62               4   \n",
      "2175                 0.13             0.59               5   \n",
      "6021                 0.56             0.63               4   \n",
      "9144                 0.16             0.89               4   \n",
      "14857                0.51             0.83               5   \n",
      "3046                 0.66             0.81               4   \n",
      "1755                 0.63             0.76               2   \n",
      "8433                 0.54             0.53               4   \n",
      "13930                0.55             0.45               3   \n",
      "14596                0.75             0.90               5   \n",
      "9023                 0.91             0.38               5   \n",
      "2757                 0.50             0.68               4   \n",
      "6441                 0.50             0.66               4   \n",
      "8276                 0.89             0.93               3   \n",
      "2192                 0.64             0.58               5   \n",
      "1742                 0.10             0.89               6   \n",
      "5233                 0.48             0.68               4   \n",
      "\n",
      "       average_montly_hours  time_spend_company  \n",
      "2032                    267                   4  \n",
      "1160                    276                   2  \n",
      "11615                   225                   8  \n",
      "2166                    129                   3  \n",
      "5668                    225                   3  \n",
      "4564                    108                   5  \n",
      "10250                   201                   2  \n",
      "854                     263                   5  \n",
      "1941                    251                   6  \n",
      "13349                   247                   2  \n",
      "12091                   246                   5  \n",
      "5520                    150                   3  \n",
      "13550                   242                   2  \n",
      "7536                    162                   4  \n",
      "547                     141                   3  \n",
      "9038                    264                   2  \n",
      "12363                   267                   5  \n",
      "4519                    124                   3  \n",
      "1296                    148                   3  \n",
      "6562                    177                   2  \n",
      "8445                    245                   4  \n",
      "5492                    173                   6  \n",
      "4697                    175                   3  \n",
      "11575                   192                   7  \n",
      "7606                    188                   5  \n",
      "13600                   182                   3  \n",
      "7596                    179                   2  \n",
      "10073                   258                   4  \n",
      "13397                   224                   3  \n",
      "9802                    266                   3  \n",
      "...                     ...                 ...  \n",
      "11193                   186                  10  \n",
      "5040                    195                   3  \n",
      "6778                     96                   2  \n",
      "1533                    146                   3  \n",
      "1789                    150                   3  \n",
      "2997                    168                   6  \n",
      "2384                    148                   2  \n",
      "11349                   221                  10  \n",
      "4993                    266                   2  \n",
      "7627                    182                   3  \n",
      "3611                    225                   3  \n",
      "12281                   301                   3  \n",
      "13901                   220                   3  \n",
      "120                     158                   4  \n",
      "2175                    160                   5  \n",
      "6021                    271                   2  \n",
      "9144                    196                   3  \n",
      "14857                   249                   4  \n",
      "3046                    148                   4  \n",
      "1755                    157                   4  \n",
      "8433                    245                   2  \n",
      "13930                   179                   2  \n",
      "14596                   256                   5  \n",
      "9023                    279                   5  \n",
      "2757                    161                   3  \n",
      "6441                    155                   2  \n",
      "8276                    181                   3  \n",
      "2192                    115                   5  \n",
      "1742                    259                   5  \n",
      "5233                    163                   2  \n",
      "\n",
      "[11249 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(features_train_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적의 모델 개발하고 테스트\n",
    "\n",
    "1. 앞의 model 평가에서 최적화된 파라미터로 선정된 것은 아래와 같다.\n",
    " - max_depth = 5,\n",
    " - min_samples = 150,\n",
    " - class_weight = \"balanced\"\n",
    "2. 그리고 위에서 어떤 feature가 더 중요하고 덜 중요한지도 살펴봤다.\n",
    " - selected_list : satisfaction_level, last_evaluation, number_project, average_montly_hours, time_spend_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.4133333333\n",
      "88.7810140237\n",
      "93.1861145216\n"
     ]
    }
   ],
   "source": [
    "# 위의 1에서 확인한 파라미터로 best_model 초기화\n",
    "model_best = DecisionTreeClassifier(max_depth=6, min_samples_leaf=150, class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "# 선택된 feature들로 훈련 데이터를 대상으로 best model을 fitting\n",
    "model_best.fit(features_train_selected, target_train)\n",
    "\n",
    "# 선택된 feature들로 테스트 데이터를 대상으로 예측 수행\n",
    "prediction_best = model_best.predict(features_test_selected)\n",
    "\n",
    "\n",
    "# model의 정확도(accuracy) 점수, recall 점수, ROC/AUC 점수 출력\n",
    "print(model_best.score(features_test_selected, target_test)*100)\n",
    "print(recall_score(prediction_best, target_test)*100)\n",
    "print(roc_auc_score(prediction_best, target_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
